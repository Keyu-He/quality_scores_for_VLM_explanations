{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import openai\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"HuggingFaceM4/A-OKVQA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import base64\n",
    "import requests\n",
    "\n",
    "with open(\"../OPENAI_key.txt\") as f:\n",
    "    # OpenAI API Key\n",
    "    api_key = f.read().split()[0]\n",
    "\n",
    "# Function to encode the image\n",
    "def encode_image(image_path):\n",
    "  with open(image_path, \"rb\") as image_file:\n",
    "    return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n",
    "headers = {\n",
    "  \"Content-Type\": \"application/json\",\n",
    "  \"Authorization\": f\"Bearer {api_key}\"\n",
    "}\n",
    "\n",
    "def query(image, prompt, max_tokens=500):\n",
    "\n",
    "    # if type(image) == str:\n",
    "    #     image = encode_image(image)\n",
    "\n",
    "    payload = {\n",
    "        \"model\": \"gpt-4-turbo\",\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\n",
    "                        \"type\": \"text\",\n",
    "                        \"text\": prompt,\n",
    "                    },\n",
    "                ]\n",
    "            }\n",
    "        ],\n",
    "        \"max_tokens\": max_tokens\n",
    "    }\n",
    "    response = requests.post(\"https://api.openai.com/v1/chat/completions\", headers=headers, json=payload)\n",
    "    print(f\"Response: {response}\")\n",
    "\n",
    "    if response.status_code != 200:\n",
    "        print(response.json())\n",
    "        return None\n",
    "    else:\n",
    "       return response.json()['choices'][0]['message']['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "def inference(image, question, mode = \"qa\"):\n",
    "  if mode == \"qa\":\n",
    "    output = query(image, question, max_tokens=50)\n",
    "  elif mode == \"rationale\":\n",
    "    output = query(image, question, max_tokens=100)\n",
    "  elif mode == \"qa_rationale\":\n",
    "    output = query(image, question)\n",
    "  \n",
    "  return output\n",
    "\n",
    "def make_prompt(x):\n",
    "  \"\"\"made so we can do some preprocessing editing to the question. left for the future\"\"\"\n",
    "  return f\"{x['question']} Choices: {', '.join(x['choices'])}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "dataset = load_dataset(\"HuggingFaceM4/A-OKVQA\")\n",
    "\n",
    "# Verify the structure of the dataset\n",
    "print(\"Dataset structure: \", dataset)\n",
    "\n",
    "# Select the first 250 examples from the training set\n",
    "infer = dataset['train'].select(range(250))\n",
    "\n",
    "# Verify the first example to confirm it's from the training set\n",
    "print(\"First training example: \", infer[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "RES_PATH = \"./results/\"\n",
    "SAVE_PATH = RES_PATH + \"img/\"\n",
    "\n",
    "import os\n",
    "\n",
    "if not os.path.exists(RES_PATH):\n",
    "    os.makedirs(RES_PATH)\n",
    "\n",
    "if not os.path.exists(RES_PATH + \"img/\"):\n",
    "    os.makedirs(RES_PATH + \"img/\")\n",
    "\n",
    "if not os.path.exists(RES_PATH + \"result/\"):\n",
    "    os.makedirs(RES_PATH + \"result/\")\n",
    "\n",
    "N = 250\n",
    "\n",
    "infer = dataset[\"train\"].select(range(250))\n",
    "# # --------- setting set-50 for testing ------------\n",
    "# set_50 = pd.read_csv(\"set-50-idx.csv\")\n",
    "# set_50_idx = set_50[\"idx\"].tolist()\n",
    "# infer = dataset[\"train\"].select(set_50_idx)\n",
    "# # --------- END setting set-50 for testing ------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to convert PIL image to base64\n",
    "import base64\n",
    "import io\n",
    "\n",
    "def pil_image_to_base64(pil_image, img_format=\"JPEG\"):\n",
    "    img_buffer = io.BytesIO()\n",
    "    pil_image.save(img_buffer, format=img_format)\n",
    "    img_buffer.seek(0)\n",
    "    return base64.b64encode(img_buffer.read()).decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "results = []\n",
    "\n",
    "for idx, x in enumerate(tqdm(infer, total=len(infer))):\n",
    "    print(x)\n",
    "    print(x['choices'])\n",
    "    print(x['choices'][x['correct_choice_idx']])\n",
    "    break\n",
    "    # Retrieve the image bytes\n",
    "    image_data = x[\"image\"].get('bytes')\n",
    "\n",
    "    # Convert bytes data to a PIL Image object\n",
    "    image = Image.open(io.BytesIO(image_data))\n",
    "    \n",
    "     # Show the image\n",
    "    plt.imshow(image)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "    # Save the image to the specified path\n",
    "    image.save(f\"{SAVE_PATH}/{idx}.jpg\")\n",
    "\n",
    "    question_and_choices = make_prompt(x)  # f\"{x['question']} Choices: {str(x['choices'])}\"\n",
    "\n",
    "    # one-shot run for qa_rationale\n",
    "#     one_shot_prompt = \"First generate the rationale for the question and then answer the question based on the rationale. Make sure to provide final answer in JSON format such as  {'answer': 'your answer'}\"\n",
    "    one_shot_prompt = \"First, generate a rationale for why you select a given answer for the following question. Follow this with the statement 'Thus, the answer is ' and then provide the answer.\"\n",
    "    qa_rationale_question =  f\"{one_shot_prompt} Question and choices: {question_and_choices}.\"\n",
    "\n",
    "    def is_correct(qa_rationale_answer, correct_answer):\n",
    "        # check if the correct_answer is in the qa_rationale_answer\n",
    "        return 1 if f'Thus, the answer is {correct_answer.lower()}' in qa_rationale_answer.lower() else 0\n",
    "\n",
    "    image = pil_image_to_base64(image)\n",
    "    qa_rationale_answer = inference(image, qa_rationale_question, mode=\"qa_rationale\")\n",
    "    \n",
    "    print(f\"qa_rationale_answer: {qa_rationale_answer}\")\n",
    "\n",
    "    print(f\"Question: {question_and_choices} \\nOne shot question: {qa_rationale_question} \\nAnswer: {qa_rationale_answer} \\nCorrect Answer: {x['choices'][x['correct_choice_idx']]}\")\n",
    "    print(f\"Is Correct: {is_correct(qa_rationale_answer, x['choices'][x['correct_choice_idx']])}\")\n",
    "    print('-'*100)\n",
    "\n",
    "    results.append(\n",
    "        {\n",
    "            \"idx\": idx,\n",
    "            \"question\": question_and_choices,\n",
    "            \"correct_answer\": x[\"choices\"][x[\"correct_choice_idx\"]],\n",
    "            \"predicted_answer\": qa_rationale_answer,\n",
    "            \"is_correct\": (\n",
    "                # 1 if qa_answer == x[\"choices\"][x[\"correct_choice_idx\"]] else 0\n",
    "                is_correct(qa_rationale_answer, x[\"choices\"][x[\"correct_choice_idx\"]])\n",
    "            ),\n",
    "            \"groundtruth_rationale\": x[\"rationales\"],\n",
    "            \"direct_answer\": x[\"direct_answers\"],\n",
    "            \"rationale_prompt\": qa_rationale_question,\n",
    "            \"generated_rationale\": qa_rationale_answer,\n",
    "            \"image_path\": f\"{SAVE_PATH}/{idx}.jpg\",\n",
    "        }\n",
    "    )\n",
    "    # print('-'*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "res_cpy = deepcopy(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "res_cpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# now we try to find the real answers via parsing the json in \n",
    "# every response and compare it with the correct answer\n",
    "import re\n",
    "import json\n",
    "\n",
    "\n",
    "def extract_answer(text):\n",
    "    try:\n",
    "        pattern = r'\\{\\s*(?:\"[^\"]*\"\\s*:\\s*\".*?\"|\\'[^\\']*\\'\\s*:\\s*\\'.*?\\')(?:\\s*,\\s*(?:\"[^\"]*\"\\s*:\\s*\".*?\"|\\'[^\\']*\\'\\s*:\\s*\\'.*?\\'))*\\s*\\}'\n",
    "        dict_str = re.search(pattern, text).group(0)\n",
    "        ans = eval(dict_str)\n",
    "        return list(ans.values())[0]\n",
    "    except:\n",
    "        return text\n",
    "\n",
    "for idx in range(len(res_cpy)):\n",
    "    \n",
    "    res_cpy[idx][\"predicted_answer\"] = extract_answer(res_cpy[idx][\"predicted_answer\"])\n",
    "    res_cpy[idx][\"is_correct\"] =  int(\n",
    "        res_cpy[idx][\"correct_answer\"].lower() in res_cpy[idx][\"predicted_answer\"].lower()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "RES_NAME = f\"gpt4o_trial2.xlsx\"\n",
    "df = pd.DataFrame(res_cpy)\n",
    "writer = pd.ExcelWriter(RES_PATH + RES_NAME, engine='xlsxwriter')\n",
    "# Convert the dataframe to an XlsxWriter Excel object.\n",
    "df.to_excel(writer, sheet_name='Sheet1')\n",
    "\n",
    "# Get the xlsxwriter workbook and worksheet objects.\n",
    "workbook  = writer.book\n",
    "worksheet = writer.sheets['Sheet1']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import xlsxwriter\n",
    "\n",
    "MODEL_ID = \"gpt-4o\"\n",
    "\n",
    "RES_NAME = f\"{MODEL_ID.split('/')[-1]}_inference_one_shot_50_improved_prompt.xlsx\"\n",
    "df = pd.DataFrame(res_cpy)\n",
    "print(RES_PATH, RES_NAME)\n",
    "\n",
    "with pd.ExcelWriter(RES_PATH + RES_NAME, engine='xlsxwriter') as writer:\n",
    "    # Write the DataFrame to the worksheet, excluding the 'ImagePath' column if you don't want it in the Excel file.\n",
    "    df.to_excel(writer, sheet_name='Sheet1', index=False)\n",
    "\n",
    "    # Access the XlsxWriter workbook and worksheet objects from the DataFrame.\n",
    "    workbook = writer.book\n",
    "    worksheet = writer.sheets['Sheet1']\n",
    "\n",
    "    # Assuming 'ImagePath' is the name of the column containing the image paths.\n",
    "    # Iterate over the DataFrame to insert images.\n",
    "    for index, data in df.iterrows():\n",
    "        # The cell where to insert the image is in column 'R', on the row corresponding to the DataFrame's index + 2\n",
    "        # (because DataFrame's index starts at 0 and Excel rows start at 1, and there's a header row).\n",
    "        cell = f'R{index + 2}'\n",
    "        image_path = data['image_path']\n",
    "\n",
    "        # Insert the image.\n",
    "        worksheet.insert_image(cell, image_path)\n",
    "        # worksheet.insert_image(cell, image_path, {'x_scale': 0.5, 'y_scale': 0.5})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jcSF6EVtlLeh"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N-301GzykTtn"
   },
   "outputs": [],
   "source": [
    "#  %%capture\n",
    "!pip install datasets\n",
    "!pip install accelerate\n",
    "!pip install xlsxwriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bY61L1KUkRVy"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"HuggingFaceM4/A-OKVQA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IlvyE61mmtAp"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "def imshow(img, ax=None, caption=\"\"):\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots()\n",
    "    if isinstance(img, Image.Image):\n",
    "        img = np.array(img)\n",
    "    # Ensure the image data type is uint8 or float32\n",
    "    if img.dtype != np.uint8 and img.dtype != np.float32:\n",
    "        img = img.astype(np.uint8)\n",
    "    # Expand dimensions if necessary\n",
    "    if img.ndim == 2:\n",
    "        img = np.expand_dims(img, axis=-1)\n",
    "    ax.imshow(img)\n",
    "    ax.set_title(caption)\n",
    "    ax.axis('off')\n",
    "    return ax\n",
    "\n",
    "def plot_images_with_captions(images, captions):\n",
    "    fig, axes = plt.subplots(nrows=len(images), ncols=1, figsize=(10, 10))\n",
    "    # If only one image, axes may not be a list\n",
    "    if len(images) == 1:\n",
    "        axes = [axes]\n",
    "    for i, (img, caption) in enumerate(zip(images, captions)):\n",
    "        ax = imshow(img, axes[i])\n",
    "        ax.set_title(caption)\n",
    "    plt.show()\n",
    "\n",
    "# Load images properly\n",
    "images = [np.array(dataset['train'][i]['image']) for i in range(2)]\n",
    "captions = [dataset['train'][i]['question'] for i in range(2)]\n",
    "plot_images_with_captions(images, captions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sRLJ1tC6w-zn"
   },
   "source": [
    "# Load model üèã"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TIJ3BTNZJThp"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "# Load model directly\n",
    "from transformers import AutoProcessor, AutoModelForPreTraining, LlavaForConditionalGeneration\n",
    "\n",
    "MODEL_ID = \"llava-hf/llava-1.5-7b-hf\"\n",
    "model = LlavaForConditionalGeneration.from_pretrained(\"llava-hf/llava-1.5-7b-hf\")\n",
    "processor = AutoProcessor.from_pretrained(\"llava-hf/llava-1.5-7b-hf\")\n",
    "\n",
    "model.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PPpY3IxBU6zR"
   },
   "outputs": [],
   "source": [
    "# prompt: get total model parameters in human readable format\n",
    "\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "human_readable_params = f\"{total_params / 1e6:.2f}M\"\n",
    "print(f\"Total Parameters: {human_readable_params}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PWKyto-upPdp"
   },
   "source": [
    "# running inference on A-OKVQA üèÉ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hmf4xBzeyrtR"
   },
   "outputs": [],
   "source": [
    "from typing import List, Dict, Any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ERgZ3r3YxZjV"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jJ4IlbcLumRq"
   },
   "outputs": [],
   "source": [
    "def inference(image, question, mode = \"qa\", hyperparams = None, max_new_tokens=40):\n",
    "  # inputs = processor(images=image, text=make_prompt({'question': question}), return_tensors=\"pt\").to(\"cuda\", torch.float16)\n",
    "  inputs = processor(text=question, images=image, return_tensors=\"pt\").to(\"cuda\")#, torch.float16)\n",
    "  if mode == \"qa\":\n",
    "      outputs = model.generate(**inputs,\n",
    "                               num_beams=5,\n",
    "                               length_penalty=-1,\n",
    "                               max_new_tokens=max_new_tokens)\n",
    "                              #  max_length=max_new_tokens)\n",
    "  elif mode == \"rationale\":\n",
    "      outputs = model.generate(**inputs,\n",
    "                               num_beams=5,\n",
    "                               length_penalty=1.1, # choose from [1, 1.5, 2]\n",
    "                               max_new_tokens=max_new_tokens,\n",
    "                               )\n",
    "                            #  max_length=max_new_tokens,\n",
    "                            #  )\n",
    "\n",
    "  # Decode and print the answer\n",
    "  answer = processor.decode(outputs[0], skip_special_tokens=True)\n",
    "  return answer\n",
    "\n",
    "def make_prompt(x):\n",
    "  \"\"\"made so we can do some preprocessing editing to the question. left for the future\"\"\"\n",
    "  return f\"{x['question']} Choices: {', '.join(x['choices'])}\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "frHgDPyaYeVR"
   },
   "source": [
    "# Helper methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mmTcao1kb4yI"
   },
   "source": [
    "# Generating Sheets for Annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n5B8mtvSb7xC"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "RES_PATH = \"/content/drive/MyDrive/<hidden>/results/\"\n",
    "SAVE_PATH = \"/content/drive/MyDrive/<hidden>/img\"\n",
    "\n",
    "import os\n",
    "if not os.path.exists(RES_PATH):\n",
    "    os.makedirs(RES_PATH)\n",
    "    os.makedirs(RES_PATH + \"img\\\\\")\n",
    "    os.makedirs(RES_PATH + \"result\\\\\")\n",
    "\n",
    "meta_prompt =  \"Please explain the reasoning behind your answer?\"\n",
    "N_SAMPLES = 250 # -1\n",
    "N = len(dataset['train'])\n",
    "\n",
    "results = []\n",
    "\n",
    "for idx, x in enumerate(tqdm(dataset['train'], total = N_SAMPLES)):\n",
    "  if idx >= N_SAMPLES:\n",
    "    break\n",
    "\n",
    "  # save image to make sheet\n",
    "  image = x['image']\n",
    "\n",
    "  # Show the image\n",
    "  plt.imshow(image)\n",
    "  plt.axis('off')\n",
    "  plt.show()\n",
    "\n",
    "  # save image\n",
    "  image.save(f'{SAVE_PATH}/{idx}.jpg')\n",
    "\n",
    "  # run inference\n",
    "  question = make_prompt(x) #f\"{x['question']} Choices: {str(x['choices'])}\"\n",
    "  print(question)\n",
    "  qa_question = f\"<image>\\nUSER:Question: {question}.\\nASSISTANT:\"\n",
    "  qa_answer = inference(image, qa_question, mode = \"qa\")\n",
    "  qa_answer = qa_answer[len(qa_question)-6:]\n",
    "  print(\"QA_ANSWER:\")\n",
    "  print(qa_answer)\n",
    "  ra_question = f\"<image>\\nUSER:Question: {question}. Answer: {qa_answer}. {meta_prompt}\\nASSISTANT:\"\n",
    "  answer = inference(image, ra_question, mode=\"rationale\", max_new_tokens=100)\n",
    "  answer = answer[len(ra_question)-6:]\n",
    "  print()\n",
    "  print(f\"question: {ra_question}\\nrationale: {answer}\")\n",
    "\n",
    "  results.append({\n",
    "      'question': question,\n",
    "      'correct_answer' : x['choices'][x['correct_choice_idx']],\n",
    "      'predicted_answer' : qa_answer,\n",
    "      'is_correct': 1 if qa_answer.lower() == x['choices'][x['correct_choice_idx']].lower() else 0,\n",
    "      'groundtruth_rationale' : x['rationales'],\n",
    "      'direct_answer' : x['direct_answers'],\n",
    "      'rationale_prompt' : ra_question,\n",
    "      'generated_rationale' : answer,\n",
    "      'image_path': f'{SAVE_PATH}/{idx}.jpg',\n",
    "  })\n",
    "\n",
    "  # print('-'*100)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vA1yjH89gofK"
   },
   "outputs": [],
   "source": [
    "RES_NAME = f\"test.xlsx\"\n",
    "df = pd.DataFrame(results)\n",
    "writer = pd.ExcelWriter(RES_PATH + RES_NAME, engine='xlsxwriter')\n",
    "# Convert the dataframe to an XlsxWriter Excel object.\n",
    "df.to_excel(writer, sheet_name='Sheet1')\n",
    "\n",
    "# Get the xlsxwriter workbook and worksheet objects.\n",
    "workbook  = writer.book\n",
    "worksheet = writer.sheets['Sheet1']\n",
    "\n",
    "# worksheet.insert_image('R1', f'/content/drive/MyDrive/<hidden>/img/{idx}.jpg')\n",
    "\n",
    "# # Close the Pandas Excel writer and output the Excel file.\n",
    "# writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GyQ3txeHe9cD"
   },
   "outputs": [],
   "source": [
    "import xlsxwriter\n",
    "\n",
    "RES_NAME = f\"{MODEL_ID.split('/')[-1].strip()}_inference.xlsx\"\n",
    "df = pd.DataFrame(results)\n",
    "print(RES_PATH, RES_NAME)\n",
    "\n",
    "with pd.ExcelWriter(RES_PATH + RES_NAME, engine='xlsxwriter') as writer:\n",
    "    # Write the DataFrame to the worksheet, excluding the 'ImagePath' column if you don't want it in the Excel file.\n",
    "    df.to_excel(writer, sheet_name='Sheet1', index=False)\n",
    "\n",
    "    # Access the XlsxWriter workbook and worksheet objects from the DataFrame.\n",
    "    workbook = writer.book\n",
    "    worksheet = writer.sheets['Sheet1']\n",
    "\n",
    "    # Assuming 'ImagePath' is the name of the column containing the image paths.\n",
    "    # Iterate over the DataFrame to insert images.\n",
    "    for index, data in df.iterrows():\n",
    "        # The cell where to insert the image is in column 'R', on the row corresponding to the DataFrame's index + 2\n",
    "        # (because DataFrame's index starts at 0 and Excel rows start at 1, and there's a header row).\n",
    "        cell = f'R{index + 2}'\n",
    "        image_path = data['image_path']\n",
    "\n",
    "        # Insert the image.\n",
    "        worksheet.insert_image(cell, image_path)\n",
    "        # worksheet.insert_image(cell, image_path, {'x_scale': 0.5, 'y_scale': 0.5})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iePjKXSEe9ob"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

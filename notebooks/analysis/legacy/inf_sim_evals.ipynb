{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "inform_sim_data_path = 'data_with_inform_sim/data_with_inform_sim_LLaVA_v2.csv'\n",
    "inform_sim_data = pd.read_csv(inform_sim_data_path)\n",
    "# inform_sim_data.drop(columns=['simulatable'], inplace=True)\n",
    "inform_sim_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Here are the steps I used to copy extracted_rationale_pieces\n",
    "I will then paste it into the human annotated data on google slides\"\"\"\n",
    "# # Drop if column K is empty\n",
    "# human_annotated_data_50 = pd.read_excel('../results/Human Annotation of LLaVA+ Rationales.xlsx', header=1).iloc[:, :14].dropna(subset=['Annotator'])\n",
    "# # Calc inform_sim_data's accuracy on the set of human annotated data\n",
    "# filtered_data_set_50 = inform_sim_data[inform_sim_data['question'].isin(human_annotated_data_50['question'])]\n",
    "# merged_data_50 = pd.merge(filtered_data_set_50[['question', 'informative', 'simulatable_mask', 'extracted_rationale_pieces']], human_annotated_data_50, on='question')\n",
    "\n",
    "# # Output a xlsx file containing only column 'extracted_rationale_pieces'\n",
    "# # For the sentences in the list in one cell, separate them by '\\n'\n",
    "# merged_data_50['extracted_rationale_pieces'] = merged_data_50['extracted_rationale_pieces'].apply(lambda x: x.replace('\\', ', '\\', \\n'))\n",
    "# # For every sentence in the list, assign a different color. Say the first sentence is red, the second is orange, the third is green, and so on.\n",
    "\n",
    "\n",
    "\n",
    "# # Save the data to a xlsx file\n",
    "# merged_data_50[['question', 'extracted_rationale_pieces']].to_excel('TEMP_extracted_rationale_pieces.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_annotated_data_path = '../results/Human Annotation of LLaVA+ Rationales.xlsx'\n",
    "# Up to column N, drop NaN rows\n",
    "human_annotated_data = pd.read_excel(human_annotated_data_path, header=1).iloc[:, :14].dropna()\n",
    "human_annotated_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(human_annotated_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_data_set_50 = inform_sim_data[inform_sim_data['question'].isin(human_annotated_data['question'])]\n",
    "len(filtered_data_set_50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data = pd.merge(filtered_data_set_50[['question', 'informative', 'simulatable_mask', 'support_use_pieces', 'support_use_pieces_mask']], human_annotated_data, on='question')\n",
    "merged_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_data_high_human_sim_info = merged_data[(merged_data['Informativeness'] == 1) & (merged_data['Simulatability'] == 1)]\n",
    "print(f'Number of high human sim info: { len(filtered_data_high_human_sim_info) }')\n",
    "filtered_data_high_human_sim_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_data_high_auto_sim_info = filtered_data_set_50[(filtered_data_set_50['informative'] == True) & (filtered_data_set_50['simulatable_mask'] == True)]\n",
    "filtered_data_high_auto_sim_info = pd.merge(filtered_data_high_auto_sim_info, human_annotated_data[['question', 'Informativeness', 'Simulatability', 'Visual Fidelity']], on='question')\n",
    "print(f'Number of high auto sim info: { len(filtered_data_high_auto_sim_info) }')\n",
    "filtered_data_high_auto_sim_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_statistics(data):\n",
    "    accuracy = np.mean(data['is_correct'])\n",
    "    avg_simulatability = np.mean(data['simulatable_mask'])\n",
    "    avg_informativeness = np.mean(data['informative'])\n",
    "    percentage_low_human_fidelity = np.mean((data['Visual Fidelity'] == 0) | (data['Visual Fidelity'] == -1))\n",
    "    print(f'Accuracy: {accuracy}')\n",
    "    print(f'Average Simulatability: {avg_simulatability}')\n",
    "    print(f'Average Informativeness: {avg_informativeness}')\n",
    "    print(f'Percentage of low human fidelity: {percentage_low_human_fidelity}')\n",
    "    print('---------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in [merged_data, filtered_data_high_human_sim_info, filtered_data_high_auto_sim_info]:\n",
    "    calc_statistics(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install seaborn scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "# Prepare the data\n",
    "merged_data['Human_Informativeness'] = merged_data['Informativeness'].apply(lambda x: 1 if x == 1 else 0)\n",
    "merged_data['Human_Simulatability'] = merged_data['Simulatability'].apply(lambda x: 1 if x == 1 else 0)\n",
    "\n",
    "# Function to reorder confusion matrix\n",
    "def reorder_confusion_matrix(conf_matrix):\n",
    "    return conf_matrix[::-1, ::-1]\n",
    "\n",
    "# Create confusion matrices\n",
    "conf_matrix_informativeness = confusion_matrix(merged_data['Human_Informativeness'], merged_data['informative'])\n",
    "conf_matrix_simulatability = confusion_matrix(merged_data['Human_Simulatability'], merged_data['simulatable'])\n",
    "\n",
    "# Reorder the confusion matrices\n",
    "conf_matrix_informativeness_reordered = reorder_confusion_matrix(conf_matrix_informativeness)\n",
    "conf_matrix_simulatability_reordered = reorder_confusion_matrix(conf_matrix_simulatability)\n",
    "\n",
    "# Plot the confusion matrices\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10, 4.5))\n",
    "\n",
    "sns.heatmap(conf_matrix_informativeness_reordered, annot=True, fmt='d', cmap='Blues', ax=ax[0])\n",
    "ax[0].set_title('Informativeness Confusion Matrix')\n",
    "ax[0].set_xlabel('Automatic')\n",
    "ax[0].set_ylabel('Human')\n",
    "ax[0].set_xticklabels(['1', '0'])\n",
    "ax[0].set_yticklabels(['1', '0'])\n",
    "\n",
    "sns.heatmap(conf_matrix_simulatability_reordered, annot=True, fmt='d', cmap='Blues', ax=ax[1])\n",
    "ax[1].set_title('Simulatability Confusion Matrix')\n",
    "ax[1].set_xlabel('Automatic')\n",
    "ax[1].set_ylabel('Human')\n",
    "ax[1].set_xticklabels(['1', '0'])\n",
    "ax[1].set_yticklabels(['1', '0'])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "# Prepare the data: 1-->1, 0/-1-->0\n",
    "merged_data['Human_Simulatability'] = merged_data['Simulatability'].apply(lambda x: 1 if x == 1 else 0)\n",
    "\n",
    "# Function to reorder confusion matrix\n",
    "def reorder_confusion_matrix(conf_matrix):\n",
    "    return conf_matrix[::-1, ::-1]\n",
    "\n",
    "# Create confusion matrices\n",
    "conf_matrix_simulatability_mask = reorder_confusion_matrix(confusion_matrix(merged_data['Human_Simulatability'], merged_data['simulatable_mask']))\n",
    "conf_matrix_simulatability_pieces = reorder_confusion_matrix(confusion_matrix(merged_data['Human_Simulatability'], merged_data['support_use_pieces']))\n",
    "conf_matrix_simulatability_pieces_mask = reorder_confusion_matrix(confusion_matrix(merged_data['Human_Simulatability'], merged_data['support_use_pieces_mask']))\n",
    "\n",
    "# Plot the confusion matrices\n",
    "fig, ax = plt.subplots(1, 3, figsize=(15, 4.5))\n",
    "\n",
    "for i in range(3):\n",
    "    conf_m_name = [conf_matrix_simulatability_mask, conf_matrix_simulatability_pieces, conf_matrix_simulatability_pieces_mask][i]\n",
    "    sns.heatmap(conf_m_name, annot=True, fmt='d', cmap='Blues', ax=ax[i])\n",
    "    ax[i].set_title(['Simulatability Mask Confusion Matrix', 'Simulatability Pieces Confusion Matrix', 'Simulatability Pieces Mask Confusion Matrix'][i])\n",
    "    ax[i].set_xlabel('Automatic')\n",
    "    ax[i].set_ylabel('Human')\n",
    "    ax[i].set_xticklabels(['1', '0'])\n",
    "    ax[i].set_yticklabels(['1', '0'])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

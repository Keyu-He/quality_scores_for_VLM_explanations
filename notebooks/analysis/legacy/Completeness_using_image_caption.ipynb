{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d756ee6",
   "metadata": {},
   "source": [
    "1. Dense image caption / Use GPT to get detailed description of the image\n",
    "    DenseCap https://google.github.io/localized-narratives/ \n",
    "2. Split into chunk of information pieces and add to the rationale, see if entailment prob changes\n",
    "3. Find examples of rationales where rationales are not complete, and check if simulatability itself captures the lack of completeness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a28947",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Use Dense Image caption to replace GPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8064eb91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "# OPENAI api key\n",
    "api_key_path = '../../OPENAI_key.txt'\n",
    "with open(api_key_path, 'r') as file:\n",
    "    api_key = file.read().strip().split('\\n')[0]\n",
    "    \n",
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "# Record the cost\n",
    "COST_FILE = \"total_cost.txt\"\n",
    "\n",
    "def read_total_cost():\n",
    "    if os.path.exists(COST_FILE):\n",
    "        with open(COST_FILE, \"r\") as file:\n",
    "            content = file.read().strip()\n",
    "            return float(content) if not content == \"\" else 0.0\n",
    "    else:\n",
    "        return 0.0\n",
    "\n",
    "def write_total_cost(cost):\n",
    "    prev_cost = read_total_cost()\n",
    "    new_total_cost = prev_cost + cost\n",
    "    with open(COST_FILE, \"w\") as file:\n",
    "        file.write(f\"{new_total_cost}\")\n",
    "        \n",
    "def calculate_cost(usage, model, verbose=0):\n",
    "    if model == \"gpt-4o-2024-05-13\":\n",
    "        input_cost_per_token = 0.005 / 1000\n",
    "        output_cost_per_token = 0.015 / 1000\n",
    "    elif model == \"gpt-4o-2024-08-06\":\n",
    "        input_cost_per_token = 0.0025 / 1000\n",
    "        output_cost_per_token = 0.010 / 1000\n",
    "    elif model == \"gpt-4o-mini-2024-07-18\":\n",
    "        input_cost_per_token = 0.00015 / 1000\n",
    "        output_cost_per_token = 0.00060 / 1000\n",
    "    \n",
    "    input_tokens = usage['prompt_tokens']\n",
    "    output_tokens = usage['completion_tokens']\n",
    "    cost = (input_tokens * input_cost_per_token) + (output_tokens * output_cost_per_token)\n",
    "    if verbose: print(f\"The cost incurred is ${cost:.3f}\")\n",
    "    write_total_cost(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c77930",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import requests\n",
    "\n",
    "def gpt_generate_dense_captions(image_path, cost_verbose=0):\n",
    "    model_name = \"gpt-4o-2024-08-06\"\n",
    "    # Read the image and convert it to base64 format\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        encoded_image = base64.b64encode(image_file.read()).decode('utf-8')\n",
    "    \n",
    "    user_input = f\"\"\"Generate a list of detailed descriptions that covers every visible detail from the image. Respond in the form of \"1. ... \\n 2. ... \\n 3. ...\". \"\"\"\n",
    "    \n",
    "    headers = {\n",
    "      \"Content-Type\": \"application/json\",\n",
    "      \"Authorization\": f\"Bearer {api_key}\"\n",
    "    }\n",
    "    payload = {\n",
    "        \"model\": model_name,\n",
    "        \"messages\": [\n",
    "            # {\n",
    "            #     \"role\": \"system\",\n",
    "            #     \"content\": [\n",
    "            #         {\n",
    "            #             \"type\": \"text\",\n",
    "            #             \"text\": system_prompt\n",
    "            #         }\n",
    "            #     ]\n",
    "            # },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\n",
    "                        \"type\": \"text\",\n",
    "                        \"text\": user_input,\n",
    "                    }, \n",
    "                    {\n",
    "                        \"type\": \"image_url\",\n",
    "                        \"image_url\": {\n",
    "                            \"url\": f\"data:image/jpeg;base64,{encoded_image}\"\n",
    "                        }\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "        ],\n",
    "    }\n",
    "    response = requests.post(\"https://api.openai.com/v1/chat/completions\", headers=headers, json=payload)\n",
    "\n",
    "    if response.status_code != 200:\n",
    "        print(response.json())\n",
    "        return None\n",
    "    else:\n",
    "        usage = response.json()['usage']\n",
    "        calculate_cost(usage, model_name, verbose=cost_verbose)\n",
    "        \n",
    "        content = response.json()['choices'][0]['message']['content'].strip()\n",
    "        \n",
    "        # content is a list of questions, separated by a newline character\n",
    "        # 1. ... \\n 2. ... \\n 3. ...\n",
    "\n",
    "        # Split the content into individual questions and return a python list\n",
    "        try:\n",
    "            parts = content.split('\\n')\n",
    "            descriptions = [part.split('. ')[1] for part in parts]\n",
    "        except(IndexError):\n",
    "            descriptions = content\n",
    "\n",
    "        return descriptions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6984fac",
   "metadata": {},
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5099c7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Read the data\n",
    "data = pd.read_excel(\"data_vf_questions_val_set_GPT_r.xlsx\").dropna().reset_index()\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f50b23fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "df = data.copy()\n",
    "df['dense_captions'] = df.progress_apply(lambda row: gpt_generate_dense_captions(row['image_path']), axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2147aa5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('data_vf_q_val_GPT_r_dense_captions.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df29e5a4",
   "metadata": {},
   "source": [
    "# Evaluate Simulatability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b59909",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = pd.read_csv('data_vf_q_val_GPT_r_dense_captions.csv')\n",
    "df = data.copy()\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "328fbfdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def generate_mask(generated_rationale, predicted_answer):\n",
    "    # Create a regex pattern to match the predicted answer case-insensitively and as a whole word\n",
    "    predicted_answer = str(predicted_answer)\n",
    "    pattern = re.compile(r'\\b' + re.escape(predicted_answer) + r'\\b', re.IGNORECASE)\n",
    "    return pattern.sub(\"<mask>\", generated_rationale)\n",
    "\n",
    "df['rationale_mask'] = df.apply(lambda row: generate_mask(row['one_step_rationale'], row['one_step_answer']), axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71891ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import requests\n",
    "\n",
    "def gpt_gen_hypothesis(question, predicted_ans, cost_verbose=0):\n",
    "    model_name = \"gpt-4o-mini-2024-07-18\"   \n",
    "    user_input = f\"\"\"Integrate the question and the answer into one sentence.\n",
    "For example, given the question \"What is the man waiting for?\" and the answer \"taxi\", you should output \"The man is waiting for taxi.\"\n",
    "\n",
    "Question: {question}\n",
    "Answer: {predicted_ans}\n",
    "\"\"\"\n",
    "    \n",
    "    headers = {\n",
    "      \"Content-Type\": \"application/json\",\n",
    "      \"Authorization\": f\"Bearer {api_key}\"\n",
    "    }\n",
    "    payload = {\n",
    "        \"model\": model_name,\n",
    "        \"messages\": [\n",
    "            # {\n",
    "            #     \"role\": \"system\",\n",
    "            #     \"content\": [\n",
    "            #         {\n",
    "            #             \"type\": \"text\",\n",
    "            #             \"text\": system_prompt\n",
    "            #         }\n",
    "            #     ]\n",
    "            # },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\n",
    "                        \"type\": \"text\",\n",
    "                        \"text\": user_input,\n",
    "                    },\n",
    "                ]\n",
    "            }\n",
    "        ],\n",
    "    }\n",
    "    response = requests.post(\"https://api.openai.com/v1/chat/completions\", headers=headers, json=payload)\n",
    "\n",
    "    if response.status_code != 200:\n",
    "        print(response.json())\n",
    "        return None\n",
    "    else:\n",
    "        usage = response.json()['usage']\n",
    "        calculate_cost(usage, model_name, verbose=cost_verbose)\n",
    "        \n",
    "        content = response.json()['choices'][0]['message']['content'].strip()\n",
    "        return content\n",
    "\n",
    "df['hypothesis'] = df.apply(lambda row: gpt_gen_hypothesis(row[\"question\"], row[\"one_step_answer\"]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69cedb17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "import torch\n",
    "\n",
    "# load the tokenizer and model only if they are not already defined\n",
    "# if 'nli_tokenizer' not in globals():\n",
    "nli_tokenizer = AutoTokenizer.from_pretrained(\"google/flan-t5-xxl\", device_map=\"cuda:9\")\n",
    "# if 'nli_model' not in globals():\n",
    "nli_model = AutoModelForSeq2SeqLM.from_pretrained(\"soumyasanyal/nli-entailment-verifier-xxl\", load_in_8bit=True, device_map=\"cuda:9\")\n",
    "\n",
    "def calc_support_prob(premise, hypothesis, nli_model=nli_model, nli_tokenizer=nli_tokenizer):\n",
    "    def get_score(nli_model, nli_tokenizer, input_ids):\n",
    "        pos_ids = nli_tokenizer('Yes').input_ids\n",
    "        neg_ids = nli_tokenizer('No').input_ids\n",
    "        pos_id = pos_ids[0]\n",
    "        neg_id = neg_ids[0]\n",
    "\n",
    "        with torch.no_grad():\n",
    "            logits = nli_model(input_ids, decoder_input_ids=torch.zeros((input_ids.size(0), 1), dtype=torch.long)).logits\n",
    "            pos_logits = logits[:, 0, pos_id]\n",
    "            neg_logits = logits[:, 0, neg_id]\n",
    "            posneg_logits = torch.cat([pos_logits.unsqueeze(-1), neg_logits.unsqueeze(-1)], dim=1)\n",
    "\n",
    "            # Cast to float before applying softmax\n",
    "            posneg_logits = posneg_logits.float()\n",
    "            scores = torch.nn.functional.softmax(posneg_logits, dim=1)\n",
    "            entail_score = scores[:, 0].item()\n",
    "            no_entail_score = scores[:, 1].item()\n",
    "        \n",
    "        return entail_score, no_entail_score\n",
    "    \n",
    "    prompt = f\"Premise: {premise}\\nHypothesis: {hypothesis}\\nGiven the premise, is the hypothesis correct?\\nAnswer:\"\n",
    "    input_ids = nli_tokenizer(prompt, return_tensors='pt').input_ids\n",
    "    return get_score(nli_model, nli_tokenizer, input_ids)[0]\n",
    "\n",
    "# def evaluate_support(data, nli_model, nli_tokenizer, use_mask=True, use_pieces=False, hypothesis_col='hypothesis', rationale_col='rationale_mask', threshold=0.5):\n",
    "#     support_scores = []\n",
    "#     for idx, row in data.iterrows():\n",
    "#         if use_pieces:\n",
    "#             premise = row['concat_rationale_pieces_mask'] if use_mask else row['concat_rationale_pieces']\n",
    "#         else: \n",
    "#             premise = row['gen_rationale_mask'] if use_mask else row['generated_rationale']\n",
    "        \n",
    "#         hypothesis = row[hypothesis_col]\n",
    "#         entail_prob = calc_support_prob(premise, hypothesis, nli_model=nli_model, nli_tokenizer=nli_tokenizer)\n",
    "#         support = entail_prob > threshold \n",
    "#         if entail_prob < threshold:\n",
    "#             print(f\"Premise: {premise}\")\n",
    "#             print(f\"Hypothesis: {hypothesis}\")\n",
    "#             print(f\"Probability: {entail_prob}\")\n",
    "#         support_scores.append({\n",
    "#             'entail_prob': entail_prob,\n",
    "#             'support': support\n",
    "#         })\n",
    "#     return support_scores\n",
    "\n",
    "df['support_score_original'] = df.apply(lambda row: calc_support_prob(row['rationale_mask'], row['hypothesis']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be0af472",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "df['dense_captions'] = data['dense_captions']\n",
    "\n",
    "def safe_literal_eval(sentence):\n",
    "    try:\n",
    "        # Try to convert the string to a Python literal (e.g., list)\n",
    "        return ast.literal_eval(sentence)\n",
    "    except (ValueError, SyntaxError):\n",
    "        # If there's a ValueError or SyntaxError, return the sentence inside a list\n",
    "        return [sentence]\n",
    "\n",
    "# Apply the function to the DataFrame column\n",
    "df['dense_captions'] = df['dense_captions'].apply(safe_literal_eval)\n",
    "\n",
    "for sentence in df['dense_captions'][0]:\n",
    "    print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34307c59",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "# Append the captions sentence by sentence to rationale_mask, see the new support score\n",
    "\n",
    "def append_captions_and_calculate(row):\n",
    "    # Copy the existing rationale mask\n",
    "    rationale_masks = []\n",
    "    # Append masks generated from each caption\n",
    "    for caption in row['dense_captions']:\n",
    "        caption_masked = generate_mask(caption, row['one_step_answer'])\n",
    "        rationale_concatted = row['rationale_mask'] + caption_masked\n",
    "        rationale_masks.append(rationale_concatted)\n",
    "    # Calculate the support probability with the updated mask\n",
    "    score_list = []\n",
    "    for rationale_concatted in rationale_masks:\n",
    "        score_list.append(calc_support_prob(rationale_concatted, row['hypothesis']))\n",
    "    return score_list\n",
    "\n",
    "# Apply the function to each row in the DataFrame, use tqdm to show the progress over rows\n",
    "tqdm.pandas(desc=\"Processing rows\")\n",
    "\n",
    "df['support_score_after_concat'] = df.progress_apply(append_captions_and_calculate, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ac3aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef86ebdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('data_vf_q_val_GPT_r_dense_captions_support_concat.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c778f3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "022bf05d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add another column to df which tells me which indices of the list in support_score_after_concat has  > 0.1 simulatability increase\n",
    "# Function to check if simulatability increase > 0.1\n",
    "def find_indices_with_increase(row):\n",
    "    original = row[\"support_score_original\"]\n",
    "    return [i for i, score in enumerate(row[\"support_score_after_concat\"]) if score - original > 0.1]\n",
    "\n",
    "# Apply the function to create the new column\n",
    "df[\"simulatability_increase_indices\"] = df.apply(find_indices_with_increase, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79838696",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a68446",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('data_vf_q_val_GPT_r_dense_captions_support_concat.csv')\n",
    "data = df.copy()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84000a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "df[\"support_score_after_concat\"] = df[\"support_score_after_concat\"].apply(ast.literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932909db",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"support_score_after_concat\"] = df[\"support_score_after_concat\"].apply(lambda x: [round(num, 3) for num in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7790ac5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f85d02a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to Excel\n",
    "output_path = \"val_qa_with_images.xlsx\"\n",
    "df.to_excel(output_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3acd84df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openpyxl import load_workbook\n",
    "from openpyxl.drawing.image import Image as ExcelImage\n",
    "import os\n",
    "\n",
    "# First, save the dataframe to an excel file (without images) to manipulate it with openpyxl\n",
    "df.to_excel(output_path, index=False)\n",
    "\n",
    "# Load the saved excel file\n",
    "wb = load_workbook(output_path)\n",
    "ws = wb.active\n",
    "\n",
    "# Add images to the new column in the excel file\n",
    "for index, row in df.iterrows():\n",
    "    img_path = row['image_path']\n",
    "    # Check if the image file exists before adding\n",
    "    if os.path.exists(img_path):\n",
    "        img = ExcelImage(img_path)\n",
    "        img_cell = f\"V{index + 2}\"  # Placing the image starting from row 2, column R\n",
    "        ws.add_image(img, img_cell)\n",
    "\n",
    "# Save the updated excel file with images\n",
    "output_path_with_images = output_path\n",
    "wb.save(output_path_with_images)\n",
    "\n",
    "output_path_with_images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d4d01e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b61d3a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c48cd95f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ebf10b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4727da27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "604aed3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a551f81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e89730b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e1435a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54cf83a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2817959d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c9d88dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "451f15a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

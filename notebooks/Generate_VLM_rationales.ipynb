{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Please run this notebook on Colab to get the correct outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "id": "r4QW8-rZocEc",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %pip install -U transformers datasets xlsxwriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "E5yv7zq2ocEc",
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "from datasets import load_dataset\n",
    "from matplotlib import pyplot as plt\n",
    "import torch\n",
    "from transformers import AutoProcessor, AutoModelForPreTraining, LlavaForConditionalGeneration\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "import xlsxwriter\n",
    "import io\n",
    "import requests\n",
    "import json\n",
    "import base64\n",
    "import re\n",
    "\n",
    "# Load the dataset\n",
    "dataset = load_dataset(\"HuggingFaceM4/A-OKVQA\")\n",
    "\n",
    "# Select the first 500 instances with images\n",
    "val_500_dataset = [dataset['validation'][i] for i in range(500)]\n",
    "N_SAMPLES = len(val_500_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g5ptJoCyocEd"
   },
   "outputs": [],
   "source": [
    "# Set up OpenAI API key\n",
    "from google.colab import userdata\n",
    "api_key = userdata.get('open_ai_api_key')\n",
    "\n",
    "# Paths for saving results (modify as needed)\n",
    "RES_PATH = \"./results/\"\n",
    "if not os.path.exists(RES_PATH):\n",
    "    os.makedirs(RES_PATH)\n",
    "\n",
    "# Define the file to store the total cost\n",
    "COST_FILE = \"total_cost.txt\"\n",
    "\n",
    "def read_total_cost():\n",
    "    if os.path.exists(COST_FILE):\n",
    "        with open(COST_FILE, \"r\") as file:\n",
    "            content = file.read().strip()\n",
    "            return float(content) if not content == \"\" else 0.0\n",
    "    else:\n",
    "        return 0.0\n",
    "\n",
    "def write_total_cost(cost):\n",
    "    prev_cost = read_total_cost()\n",
    "    new_total_cost = prev_cost + cost\n",
    "    with open(COST_FILE, \"w\") as file:\n",
    "        file.write(f\"{new_total_cost}\")\n",
    "\n",
    "def calculate_cost(usage, model, verbose=0):\n",
    "    if model == \"gpt-4o-2024-05-13\":\n",
    "        input_cost_per_token = 0.005 / 1000\n",
    "        output_cost_per_token = 0.015 / 1000\n",
    "    if model == \"gpt-4o-2024-08-06\":\n",
    "        input_cost_per_token = 0.0025 / 1000\n",
    "        output_cost_per_token = 0.010 / 1000\n",
    "\n",
    "    input_tokens = usage['prompt_tokens']\n",
    "    output_tokens = usage['completion_tokens']\n",
    "    cost = (input_tokens * input_cost_per_token) + (output_tokens * output_cost_per_token)\n",
    "    if verbose: print(f\"The cost incurred is ${cost:.3f}\")\n",
    "    write_total_cost(cost)\n",
    "\n",
    "def pil_image_to_base64(pil_image, img_format=\"JPEG\"):\n",
    "    img_buffer = io.BytesIO()\n",
    "    pil_image.save(img_buffer, format=img_format)\n",
    "    img_buffer.seek(0)\n",
    "    return base64.b64encode(img_buffer.read()).decode('utf-8')\n",
    "\n",
    "# Function to create prompt (you can modify this if needed)\n",
    "def make_prompt(x):\n",
    "    return f\"{x['question']} Choices: {', '.join(x['choices'])}\"\n",
    "\n",
    "# Define inference functions for LLaVA and GPT-4 models\n",
    "def inference_llava(model, processor, image, question, with_image=True, mode=\"qa\", max_new_tokens=40):\n",
    "    if with_image:\n",
    "        inputs = processor(text=question, images=image, return_tensors=\"pt\").to(\"cuda\")\n",
    "    else:\n",
    "        # Create a blank image when with_image is False\n",
    "        blank_image = Image.new('RGB', (224, 224), color='white')\n",
    "        inputs = processor(text=question, images=blank_image, return_tensors=\"pt\").to(\"cuda\")\n",
    "    if mode == \"qa\":\n",
    "        outputs = model.generate(**inputs,\n",
    "                                 num_beams=5,\n",
    "                                 length_penalty=-1,\n",
    "                                 max_new_tokens=max_new_tokens)\n",
    "    elif mode == \"rationale\":\n",
    "        outputs = model.generate(**inputs,\n",
    "                                 num_beams=5,\n",
    "                                 length_penalty=1.1,\n",
    "                                 max_new_tokens=max_new_tokens)\n",
    "    answer = processor.decode(outputs[0], skip_special_tokens=True)\n",
    "    return answer\n",
    "\n",
    "def inference_gpt4(image, question, with_image=True, max_tokens=100):\n",
    "    headers = {\n",
    "      \"Content-Type\": \"application/json\",\n",
    "      \"Authorization\": f\"Bearer {api_key}\"\n",
    "    }\n",
    "\n",
    "    if not with_image:\n",
    "        payload = {\n",
    "            \"model\": \"gpt-4o-2024-08-06\",\n",
    "            \"messages\": [\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": [\n",
    "                        {\n",
    "                            \"type\": \"text\",\n",
    "                            \"text\": question,\n",
    "                        }\n",
    "                    ]\n",
    "                }\n",
    "            ],\n",
    "            \"max_tokens\": max_tokens\n",
    "        }\n",
    "    else:\n",
    "        payload = {\n",
    "            \"model\": \"gpt-4o-2024-08-06\",\n",
    "            \"messages\": [\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": [\n",
    "                        {\n",
    "                            \"type\": \"text\",\n",
    "                            \"text\": question,\n",
    "                        },\n",
    "                        {\n",
    "                            \"type\": \"image_url\",\n",
    "                            \"image_url\": {\n",
    "                                \"url\": f\"data:image/jpeg;base64,{image}\"\n",
    "                            }\n",
    "                        }\n",
    "                    ]\n",
    "                }\n",
    "            ],\n",
    "            \"max_tokens\": max_tokens\n",
    "        }\n",
    "    response = requests.post(\"https://api.openai.com/v1/chat/completions\", headers=headers, json=payload)\n",
    "\n",
    "    if response.status_code != 200:\n",
    "        print(response.json())\n",
    "        return None\n",
    "    else:\n",
    "        usage = response.json()['usage']\n",
    "        model_name = response.json()['model']\n",
    "        calculate_cost(usage, model_name)\n",
    "        return response.json()['choices'][0]['message']['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "NG6u6er9ocEd",
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Load LLaVA model and processor\n",
    "MODEL_ID_LLAVA = \"llava-hf/llava-1.5-7b-hf\"\n",
    "model_llava = LlavaForConditionalGeneration.from_pretrained(MODEL_ID_LLAVA, torch_dtype=torch.bfloat16)\n",
    "processor_llava = AutoProcessor.from_pretrained(MODEL_ID_LLAVA)\n",
    "model_llava.to(\"cuda\")\n",
    "\n",
    "# Define configurations\n",
    "configs = [\n",
    "    {'model_name': 'llava', 'with_image': True, 'sheet_name': 'LLaVA-1.5 with image'},\n",
    "    {'model_name': 'llava', 'with_image': False, 'sheet_name': 'LLaVA-1.5 without image'},\n",
    "    {'model_name': 'gpt-4o', 'with_image': True, 'sheet_name': 'GPT-4o with image'},\n",
    "    {'model_name': 'gpt-4o', 'with_image': False, 'sheet_name': 'GPT-4o without image'},\n",
    "]\n",
    "\n",
    "# Define save path\n",
    "SAVE_PATH = \"./images/\"\n",
    "if not os.path.exists(SAVE_PATH):\n",
    "    os.makedirs(SAVE_PATH)\n",
    "\n",
    "for idx, x in enumerate(tqdm(val_500_dataset, total=N_SAMPLES)):\n",
    "    image = x['image']\n",
    "    image.save(f\"{SAVE_PATH}/{idx}.jpg\")\n",
    "\n",
    "# Initialize list to store all results\n",
    "all_results = []\n",
    "\n",
    "# Iterate over each configuration\n",
    "for config in configs:\n",
    "    model_name = config['model_name']\n",
    "    with_image = config['with_image']\n",
    "    sheet_name = config['sheet_name']\n",
    "\n",
    "    print(f\"Processing configuration: {sheet_name}\")\n",
    "\n",
    "    results = []\n",
    "\n",
    "    if model_name == 'llava':\n",
    "        # Meta prompt for rationale\n",
    "        meta_prompt = \"Please explain the reasoning behind your answer?\"\n",
    "\n",
    "        model = model_llava\n",
    "        processor = processor_llava\n",
    "\n",
    "        for idx, x in enumerate(tqdm(val_500_dataset, total=N_SAMPLES)):\n",
    "            image = x['image'] if with_image else None\n",
    "\n",
    "            # Prepare question\n",
    "            question = make_prompt(x)\n",
    "            qa_question = f\"<image>\\nUSER:Question: {question}.\\nASSISTANT:\"\n",
    "            qa_answer = inference_llava(model, processor, image, qa_question, with_image=with_image, mode=\"qa\", max_new_tokens=15)\n",
    "            qa_answer = qa_answer[len(qa_question)-6:].strip().strip('.')\n",
    "\n",
    "            correct_answer = x['choices'][x['correct_choice_idx']]\n",
    "            # print(f\"Question: {qa_question}\\nPredicted Answer: {qa_answer} \\tCorrect Answer: {correct_answer}\")\n",
    "\n",
    "            ra_question = f\"<image>\\nUSER:Question: {question}. Answer: {qa_answer}. {meta_prompt}\\nASSISTANT:\"\n",
    "            rationale = inference_llava(model, processor, image, ra_question, with_image=with_image, mode=\"rationale\", max_new_tokens=300)\n",
    "            rationale = rationale[len(ra_question)-6:].strip()\n",
    "\n",
    "            results.append({\n",
    "                'question': question,\n",
    "                'predicted_answer': qa_answer,\n",
    "                'correct_answer': correct_answer,\n",
    "                'is_correct': 1 if qa_answer.lower() == correct_answer.lower() else 0,\n",
    "                'generated_rationale': rationale,\n",
    "                'image_path': f\"{SAVE_PATH}{idx}.jpg\",\n",
    "            })\n",
    "\n",
    "    elif model_name == 'gpt-4o':\n",
    "        for idx, x in enumerate(tqdm(val_500_dataset, total=N_SAMPLES)):\n",
    "            image = x['image'] if with_image else None\n",
    "\n",
    "            # Prepare question\n",
    "            question = make_prompt(x)\n",
    "\n",
    "            one_shot_prompt = \"First, generate a rationale for why you select a given answer for the following question. Follow this with the statement 'Thus, the answer is ' and then provide the answer.\"\n",
    "            qa_rationale_question =  f\"{one_shot_prompt} Question and choices: {question}.\"\n",
    "\n",
    "            image = pil_image_to_base64(image) if with_image else None\n",
    "            qa_rationale_answer = inference_gpt4(image, qa_rationale_question, with_image=with_image, max_tokens=300)\n",
    "\n",
    "            # Extract qa_answer from qa_rationale_answer\n",
    "            if 'Thus, the answer is' in qa_rationale_answer:\n",
    "                qa_answer = qa_rationale_answer.split('Thus, the answer is')[-1]\n",
    "                qa_answer = qa_answer.strip(' .\\'\"`')  # Remove surrounding ., space, and quotes\n",
    "            else:\n",
    "                # Fallback if the expected phrase is not found\n",
    "                qa_answer = qa_rationale_answer.strip().split('\\n')[-1]\n",
    "                qa_answer = qa_answer.strip(' .\\'\"`')  # Remove surrounding ., space, and quotes\n",
    "\n",
    "            correct_answer = x['choices'][x['correct_choice_idx']]\n",
    "            results.append({\n",
    "                'question': question,\n",
    "                'predicted_answer': qa_answer,\n",
    "                'correct_answer': correct_answer,\n",
    "                'is_correct': 1 if qa_answer.lower() == correct_answer.lower() else 0,\n",
    "                'generated_rationale': qa_rationale_answer,\n",
    "                'image_path': f\"{SAVE_PATH}{idx}.jpg\",\n",
    "            })\n",
    "\n",
    "    # Store results in a DataFrame\n",
    "    df = pd.DataFrame(results)\n",
    "    all_results.append({'sheet_name': sheet_name, 'df': df})\n",
    "\n",
    "# Save all results to an Excel file with separate sheets, including images\n",
    "RES_NAME = \"results.xlsx\"\n",
    "with pd.ExcelWriter(os.path.join(RES_PATH, RES_NAME), engine='xlsxwriter') as writer:\n",
    "    for result in all_results:\n",
    "        sheet_name = result['sheet_name'][:31]  # Excel sheet name limit is 31 characters\n",
    "        df = result['df']\n",
    "        # Write the DataFrame to the worksheet, excluding the 'image_path' column\n",
    "        df.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "\n",
    "        # Access the XlsxWriter workbook and worksheet objects from the DataFrame\n",
    "        workbook = writer.book\n",
    "        worksheet = writer.sheets[sheet_name]\n",
    "\n",
    "        # Set the width of the image column\n",
    "        worksheet.set_column('H:H', 20)\n",
    "\n",
    "        # Iterate over the DataFrame to insert images\n",
    "        for idx, data in df.iterrows():\n",
    "            # Assuming the image is to be inserted in column 'H'\n",
    "            cell = f'H{idx + 2}'  # +2 accounts for header row\n",
    "            image_path = data['image_path']\n",
    "\n",
    "            # Insert the image into the worksheet\n",
    "            worksheet.insert_image(cell, image_path, {'x_scale': 0.5, 'y_scale': 0.5})\n",
    "\n",
    "print(f\"Results saved to {os.path.join(RES_PATH, RES_NAME)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D7UY6WB-ocEe"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
